{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46b550e-4792-4933-9ae8-7c6ab232a952",
   "metadata": {},
   "source": [
    "# Running this file requires a bunch of stuff to be run first. You'll probably need to start with reshape_and_analyze.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0f6003-f19f-4bab-986c-784a641d0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import ast\n",
    "import sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b77ed29-937a-427b-ae9a-ae502beec6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the subset so you can see what row corresponds to what\n",
    "\n",
    "filename = \"../EDA/millionsong_subset.csv\"\n",
    "subset = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc3fb80-9ff5-4045-8b93-a4ce39ab139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in values\n",
    "#only do these one at a time, because otherwise there may be memory issues.\n",
    "#alternatively, if you've got a computer that can handle it, give it a shot. \n",
    "#just make sure to restart the kernel and not run anything else at the time.\n",
    "\n",
    "pitches = pd.read_csv('pitches_half.csv', index_col = 'Unnamed: 0')\n",
    "timbre = pd.read_csv('segments_timbre_unpacked_95_percent_nonnan.csv', index_col = 'Unnamed: 0')\n",
    "non_nest = pd.read_csv('95_percent_full_non_nested_list_columns.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63f1f604-165d-4016-9d82-a0e775f5a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops any column where null values consitute more than x percentage of the material\n",
    "def drop_na_cols(df, threshold = 0.95): \n",
    "    df_isnan_sum = df.isna().sum()\n",
    "    df_isnan_bool = (df_isnan_sum <= df.shape[0] * threshold) == True\n",
    "    df_isnan_bool = df_isnan_bool[df_isnan_bool].index\n",
    "    df = df[df_isnan_bool]\n",
    "    return df\n",
    "\n",
    "# Imputes the music-related data by repeating it until it fills the row\n",
    "# Basically, this amount to repeating a song X number of times until it takes the same amount of space as the longest song in the dataset.\n",
    "# Kind of a crummy method, but it worked better than using means or constants, as far as I can tell\n",
    "def fill_row(row):\n",
    "    valid_values = row.dropna().values \n",
    "    if len(valid_values) == 0:\n",
    "        return pd.Series([-1 for _ in range(len(row))])  # Return -1 if no valid values\n",
    "    else: \n",
    "        repeat_count = (len(row) // len(valid_values)) + 1 \n",
    "        filled_row = np.tile(valid_values, repeat_count)[: len(row)] \n",
    "        return pd.Series(filled_row, index=row.index)  \n",
    "\n",
    "#See above. Basically applies this to the entire dataset. Also thresholds it.\n",
    "# I re-call the drop_na_cols at the end to remove anything where there might still be a null value, which shouldn't happen but does sometimes.\n",
    "def fill_impute(df,threshold=0.95): \n",
    "    df = drop_na_cols(df,threshold=threshold)\n",
    "    df = df.apply(fill_row,axis=1)\n",
    "    df.columns = df.columns.astype(str)\n",
    "    df = drop_na_cols(df,threshold = 0)\n",
    "    return df\n",
    "\n",
    "# Utility function for running a PCA, because I'm lazy. \n",
    "def foolproof_PCA(df,components):\n",
    "    scaling = StandardScaler()\n",
    "    df = scaling.fit_transform(df)\n",
    "    use_pca = PCA(n_components=components)\n",
    "    pcafit = use_pca.fit(df)\n",
    "    exp_var = pcafit.explained_variance_ratio_\n",
    "    pca_performed = use_pca.transform(df)\n",
    "    return exp_var, pca_performed\n",
    "\n",
    "# Gets cosine similarities between one row and every other row, then sorts it in descending order of similarity\n",
    "def get_cossim(d, reference, index): \n",
    "    a = d[index, :].reshape(1, -1)  # Query vector\n",
    "    similarities = cosine_similarity(a, d)[0]  # Compute similarity for all rows\n",
    "    outlist = sorted(enumerate(similarities), key=lambda x: -x[1]) \n",
    "    return outlist\n",
    "\n",
    "# Runs through original data set and prints out artist names and artist terms. Mostly for checking if the rest of this is working well.\n",
    "def check_artists(inlist, reference,listlen=10):\n",
    "    get_terms = lambda x: ast.literal_eval(reference.iloc[inlist[x][0]]['artist_terms'])[0:5]\n",
    "    print('\\n'.join([str((inlist[i][0],reference.iloc[inlist[i][0]]['artist_name'], get_terms(i),inlist[i][1])) for i in range(listlen)]))\n",
    "\n",
    "\n",
    "# Combines and and weights the measurements from earlier\n",
    "def combine_cos_sims(inlist, weights = None):\n",
    "    if weights == None: \n",
    "        weights = [1 for _ in inlist]\n",
    "    #else: \n",
    "        #weights = [i/sum(weights) for i in weights]\n",
    "    inlist = [sorted(i, key = lambda x: x[0]) for i in inlist]\n",
    "    print([len(i) for i in inlist])\n",
    "    inlist = [(inlist[0][i][0], sum([(inlist[j][i][1]*weights[j]) for j in range(len(inlist))])) for i in range(len(inlist[0]))]\n",
    "    #inlist = [(inlist[0][i][0], sum([(inlist[j][i][1]*weights[j]) **2 for j in range(len(inlist))])**0.5) for i in range(len(inlist[0]))]\n",
    "    return sorted(inlist, key = lambda x: -x[1])\n",
    "\n",
    "def similar_artists_id_and_cossim(df, index): \n",
    "    row = df.iloc[index]\n",
    "    sorted_row = row[2:len(row)].sort_values(ascending=False)\n",
    "    #outlist = [(sorted_row.index[i], sorted_row.iloc[i], df['artist_name'].iloc[sorted_row.index[i]]) for i in range(len(sorted_row))]\n",
    "    outlist = [(sorted_row.index[i], sorted_row.iloc[i]) for i in range(len(sorted_row))]\n",
    "    return outlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818a5022-4bcd-4e3c-81b1-746b35b4bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For timbre\n",
    "\n",
    "timbre = fill_impute(timbre)\n",
    "#timbre.to_csv('timbre_imputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000fd283-712c-433d-a271-26925f68393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pitch\n",
    "pitches = fill_impute(pitches)\n",
    "#pitches.to_csv('pitches_imputed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ac890c-aa50-4bb8-8955-9fc0a974b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches_exp_var, pitches_PCA = foolproof_PCA(pitches, 2000)\n",
    "timbre_exp_var, timbre_PCA = foolproof_PCA(timbre,2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d30be-082f-4733-a4ae-e3458c203499",
   "metadata": {},
   "source": [
    "At this point, let's go over the non_nested list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03528032-598f-42b1-8775-dfd70190933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_column_list = ['_'.join(i.split('_')[0:2]) for i in non_nest.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ee4358-3a1a-4e54-80ea-625c1b3b8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_column_uniques = list(set(split_column_list))\n",
    "split_column_dict = {split_column_uniques[i]:i for i in range(len(split_column_uniques))}\n",
    "split_column_numbered = [(split_column_list[i], split_column_dict[split_column_list[i]],i) for i in range(len(split_column_list))]\n",
    "\n",
    "non_nest_full_imp = None\n",
    "\n",
    "for subset_key in split_column_dict.keys(): \n",
    "    subset_index = split_column_dict[subset_key]\n",
    "    split_indices = [i[2] for i in split_column_numbered if i[1] == subset_index]\n",
    "    selected_columns = non_nest.columns[split_indices]\n",
    "    non_nest_subset = non_nest[selected_columns]\n",
    "    non_nest_subset.columns = non_nest_subset.columns.astype(str)\n",
    "    non_nest_subset_imp = fill_impute(non_nest_subset)\n",
    "    if type(non_nest_full_imp) == type(None): \n",
    "        non_nest_full_imp = non_nest_subset_imp\n",
    "    else: \n",
    "        non_nest_full_imp = pd.concat([non_nest_full_imp,non_nest_subset_imp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7bee1e-d8a3-4386-88be-38d151225afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nest_exp_var, non_nest_PCA = foolproof_PCA(non_nest_full_imp, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2bfd8eb-c3ef-4513-8eef-31e8fbb7d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_PCA = pd.read_csv('artist_term_components.csv',index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9702f100-3fcf-44e5-bdcf-97a4e853da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relevant_artist_columns', 'rb') as f: \n",
    "    similar_artists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54de542a-de92-4bfe-a69f-3a81daf970d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_row = 910\n",
    "\n",
    "non_nest_PCA_checklist = get_cossim(non_nest_PCA, subset, compare_row)\n",
    "#non_nest_checklist = get_cossim(non_nest_full_imp.to_numpy(),subset,compare_row)\n",
    "pitches_PCA_checklist  = get_cossim(pitches_PCA,subset,compare_row)\n",
    "#pitches_checklist = get_cossim(pitches.to_numpy(),subset,compare_row)\n",
    "timbre_PCA_checklist = get_cossim(timbre_PCA,subset,compare_row)\n",
    "#timbre_checklist = get_cossim(timbre.to_numpy(),subset,compare_row)\n",
    "genre_PCA_checklist = get_cossim(genre_PCA.to_numpy(),subset,compare_row)\n",
    "similar_artists_checklist = similar_artists_id_and_cossim(similar_artists,compare_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20f6f141-a2e8-45db-81af-ab5a1899f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 10000, 10000, 10000, 10000]\n"
     ]
    }
   ],
   "source": [
    "use_list = [non_nest_PCA_checklist,pitches_PCA_checklist,timbre_PCA_checklist,genre_PCA_checklist,similar_artists_checklist]\n",
    "#use_list = [non_nest_checklist,pitches_checklist,timbre_checklist,genre_PCA_checklist]\n",
    "weights = [4,0.5,5,5,5]\n",
    "#weights = [1,1,1,1]\n",
    "#weights=[0,1,0,0]\n",
    "\n",
    "cossim_combined = combine_cos_sims(use_list,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "609a474b-6ac6-4dc5-9015-e1f402f25e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, \"b'Finntroll'\", [b'heavy metal', b'viking metal', b'folk rock', b'black metal', b'progressive trance'], np.float64(19.499999999999986))\n",
      "(1485, \"b'Finntroll'\", [b'heavy metal', b'viking metal', b'folk rock', b'black metal', b'progressive trance'], np.float64(16.261640343511576))\n",
      "(5984, \"b'Finntroll'\", [b'heavy metal', b'viking metal', b'folk rock', b'black metal', b'progressive trance'], np.float64(15.252781375854784))\n",
      "(7777, \"b'Finntroll'\", [b'heavy metal', b'viking metal', b'folk rock', b'black metal', b'progressive trance'], np.float64(15.249437389957688))\n",
      "(3027, \"b'Finntroll'\", [b'heavy metal', b'viking metal', b'folk rock', b'black metal', b'progressive trance'], np.float64(14.853312254576537))\n",
      "(5641, \"b'Elvenking'\", [b'folk metal', b'heavy metal', b'speed metal', b'power metal', b'viking metal'], np.float64(13.476437286706217))\n",
      "(6185, \"b'Elvenking'\", [b'folk metal', b'heavy metal', b'speed metal', b'power metal', b'viking metal'], np.float64(13.25422849183229))\n",
      "(233, \"b'Moonsorrow'\", [b'viking metal', b'sympho black metal', b'doom metal', b'tech house', b'black metal'], np.float64(12.772372721290077))\n",
      "(751, \"b'Ensiferum'\", [b'power metal', b'black metal', b'heavy metal', b'finish', b'metal'], np.float64(12.682653887556489))\n",
      "(1888, \"b'Mithotyn'\", [b'viking metal', b'black metal', b'progressive trance', b'folk metal', b'trance'], np.float64(12.42272949380271))\n",
      "(6491, \"b'Skyforger'\", [b'viking metal', b'folk rock', b'black metal', b'folk metal', b'neofolk'], np.float64(12.124250094811217))\n",
      "(2619, \"b'Eluveitie'\", [b'death metal', b'hard rock', b'metal', b'rock', b'folk metal'], np.float64(12.106415499632089))\n",
      "(7314, 'b\"Old Man\\'s Child\"', [b'sympho black metal', b'black metal', b'melodic black metal', b'viking metal', b'extreme metal'], np.float64(11.688252548214393))\n",
      "(7760, \"b'YGGDRASIL'\", [b'viking metal', b'folk metal', b'dark wave', b'progressive house', b'black metal'], np.float64(11.686111839724923))\n",
      "(6279, \"b'Soilwork'\", [b'death metal', b'heavy metal', b'rock', b'metal', b'sweden'], np.float64(11.628059967453169))\n",
      "(6172, \"b'Mithotyn'\", [b'viking metal', b'black metal', b'progressive trance', b'folk metal', b'trance'], np.float64(11.456442388175955))\n",
      "(3048, 'b\"Old Man\\'s Child\"', [b'sympho black metal', b'black metal', b'melodic black metal', b'viking metal', b'extreme metal'], np.float64(11.407314789258004))\n",
      "(5056, \"b'Korpiklaani'\", [b'folk rock', b'heavy metal', b'metal', b'folk', b'folk metal'], np.float64(11.390814003660442))\n",
      "(1780, \"b'Emperor'\", [b'heavy metal', b'black metal', b'sympho black metal', b'hard trance', b'death metal'], np.float64(11.36928032173143))\n",
      "(6113, \"b'Elvenking'\", [b'folk metal', b'heavy metal', b'speed metal', b'power metal', b'viking metal'], np.float64(11.337945641602273))\n"
     ]
    }
   ],
   "source": [
    "check_artists(cossim_combined,subset,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d44610-c667-417f-b485-eefde131fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
